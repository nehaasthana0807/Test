{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuW4mdv92S8X"
      },
      "source": [
        "# Session 5 - Increased Model Complexity\n",
        "\n",
        "\n",
        "Python Notebook [Colab/Jupyter] includes:\n",
        "* Important libraries overview\n",
        "* Model selection -logistic regression, decision treerandom forest & xgboost\n",
        "* Scale with standard scaler\n",
        "* Split data - train, test, validation\n",
        "* Compare models\n",
        "* Advanced model building\n",
        "* Hyperparameter tuning -  quick high level overview\n",
        "* Model optimization - quick high level overview\n",
        "* Evaluation metrics\n",
        "* Testing accuracy\n",
        "* Pycaret for comparring models? - *Bonus session\n",
        "* Can you improve the model? Regularization, Stacking - *Bonus sesssion\n",
        "* Use case integration and model deployment - *Bonus session\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXYvQ6qsxD5v"
      },
      "source": [
        "Import your necessary libraries and packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ULcm108D42x",
        "outputId": "b0526e4f-e89a-4319-cebb-d993bee85867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heU1rn7A2Whs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import xgboost as xgb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "_wVxGu1oxhYn",
        "outputId": "67a46603-f037-46fa-f39d-66ad05a51bd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Acousticness  Danceability  Duration    Energy  Instrumentalness  Key  \\\n",
              "0     -0.682956      1.332913 -0.508052 -1.179049         -0.407036    2   \n",
              "1      0.044243      0.773779  0.983794 -1.535847         -0.464896    1   \n",
              "2     -0.589746      1.363976 -0.738452 -1.283709         -0.486428    2   \n",
              "3      1.604177     -0.773161 -0.571307 -1.635750          1.381537    5   \n",
              "4     -0.028939      0.369959  1.788174 -0.574871          1.388866    5   \n",
              "\n",
              "   Liveness  Loudness  Mode  Speechiness     Tempo  Time_Signature   Valence  \\\n",
              "0 -0.165984 -0.457521     1     3.777457  1.066649               4 -0.855011   \n",
              "1 -0.346011 -0.885152     1    -0.146977  1.442230               4  0.367140   \n",
              "2 -0.204561 -0.018972     1     2.192503 -1.744977               4 -1.312305   \n",
              "3 -0.634054 -2.172574     1    -0.741893 -1.316813               4 -1.081634   \n",
              "4  1.595710 -1.217193     0    -0.258593  1.963980               4  1.645946   \n",
              "\n",
              "   Target  TempoVariability  TempoRange  \n",
              "0       1          1.000249     6.42666  \n",
              "1       1          1.000249     6.42666  \n",
              "2       1          1.000249     6.42666  \n",
              "3       1          1.000249     6.42666  \n",
              "4       1          1.000249     6.42666  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f2b245b-2bdf-4071-bbb9-42e63f7b23f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acousticness</th>\n",
              "      <th>Danceability</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Energy</th>\n",
              "      <th>Instrumentalness</th>\n",
              "      <th>Key</th>\n",
              "      <th>Liveness</th>\n",
              "      <th>Loudness</th>\n",
              "      <th>Mode</th>\n",
              "      <th>Speechiness</th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Time_Signature</th>\n",
              "      <th>Valence</th>\n",
              "      <th>Target</th>\n",
              "      <th>TempoVariability</th>\n",
              "      <th>TempoRange</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.682956</td>\n",
              "      <td>1.332913</td>\n",
              "      <td>-0.508052</td>\n",
              "      <td>-1.179049</td>\n",
              "      <td>-0.407036</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.165984</td>\n",
              "      <td>-0.457521</td>\n",
              "      <td>1</td>\n",
              "      <td>3.777457</td>\n",
              "      <td>1.066649</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.855011</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000249</td>\n",
              "      <td>6.42666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.044243</td>\n",
              "      <td>0.773779</td>\n",
              "      <td>0.983794</td>\n",
              "      <td>-1.535847</td>\n",
              "      <td>-0.464896</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.346011</td>\n",
              "      <td>-0.885152</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146977</td>\n",
              "      <td>1.442230</td>\n",
              "      <td>4</td>\n",
              "      <td>0.367140</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000249</td>\n",
              "      <td>6.42666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.589746</td>\n",
              "      <td>1.363976</td>\n",
              "      <td>-0.738452</td>\n",
              "      <td>-1.283709</td>\n",
              "      <td>-0.486428</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.204561</td>\n",
              "      <td>-0.018972</td>\n",
              "      <td>1</td>\n",
              "      <td>2.192503</td>\n",
              "      <td>-1.744977</td>\n",
              "      <td>4</td>\n",
              "      <td>-1.312305</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000249</td>\n",
              "      <td>6.42666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.604177</td>\n",
              "      <td>-0.773161</td>\n",
              "      <td>-0.571307</td>\n",
              "      <td>-1.635750</td>\n",
              "      <td>1.381537</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.634054</td>\n",
              "      <td>-2.172574</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.741893</td>\n",
              "      <td>-1.316813</td>\n",
              "      <td>4</td>\n",
              "      <td>-1.081634</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000249</td>\n",
              "      <td>6.42666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.028939</td>\n",
              "      <td>0.369959</td>\n",
              "      <td>1.788174</td>\n",
              "      <td>-0.574871</td>\n",
              "      <td>1.388866</td>\n",
              "      <td>5</td>\n",
              "      <td>1.595710</td>\n",
              "      <td>-1.217193</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.258593</td>\n",
              "      <td>1.963980</td>\n",
              "      <td>4</td>\n",
              "      <td>1.645946</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000249</td>\n",
              "      <td>6.42666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f2b245b-2bdf-4071-bbb9-42e63f7b23f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f2b245b-2bdf-4071-bbb9-42e63f7b23f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f2b245b-2bdf-4071-bbb9-42e63f7b23f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# read the cleaned data\n",
        "df = pd.read_csv('/content/clean_data.csv') # use cleaned data from Session 3!\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBXZPJxs908w"
      },
      "source": [
        "Data Preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3IltL1N997C"
      },
      "source": [
        "**Scale the data**\n",
        "\n",
        "In many cases, **StandardScaler is a good default choice** for the following reasons:\n",
        "\n",
        "**Outlier Handling:** StandardScaler is less affected by outliers than MinMaxScaler. In MinMaxScaler, if your data has outliers, they might end up squishing the rest of the data into a narrow range close to the minimum value. StandardScaler, on the other hand, does not have a fixed range and is less affected by extreme values.\n",
        "\n",
        "**Algorithm Requirements:** Some algorithms assume that the data is normally distributed, or at least symmetrically distributed, around the mean. StandardScaler makes the mean of each feature 0 and scales the feature to unit variance, which can be a good preprocessing step if your algorithm makes this assumption.\n",
        "\n",
        "**Interpretability:** After standardization, the values of the features represent how many standard deviations they are away from the mean. This can sometimes be easier to interpret than the range used in MinMaxScaler.\n",
        "\n",
        "However, it's important to note that not all data and not all algorithms benefit from standardization. For example, if your data has a natural minimum and maximum value and does not contain outliers, MinMaxScaler might be a better choice. Similarly, some algorithms, like decision tree-based algorithms, do not require feature scaling at all.\n",
        "\n",
        "For the Spotify Song Attributes dataset, the features are various attributes of the songs like 'acousticness', 'danceability', 'energy', etc. These features are likely to have different scales and could contain outliers, so using StandardScaler could be a reasonable choice.\n",
        "\n",
        "Also, even though scaling is not necessary for tree-based models because they are not sensitive to scale, it might still be beneficial if you're comparing these models with other models that do require scaling, or if you're using regularization or feature importance methods that are sensitive to the scale of the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ_eXlRnERMv"
      },
      "source": [
        "Prepare and split the data into train and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZEiKGCuVy3e",
        "outputId": "68c24b83-685c-43f2-bce9-3451be775c99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1015\n",
              "0     997\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#checking class imbalance\n",
        "df['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6swojXfoV8Z4",
        "outputId": "005823ce-1a06-49d1-b00a-0682493deab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    50.447316\n",
              "0    49.552684\n",
              "Name: Target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "Target_count = df['Target'].value_counts()\n",
        "(Target_count)/ len(df) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srkQYoxaXpWp"
      },
      "source": [
        "We observe that the class imbalance between 1 and 0 is negligble thus we move forward and standardize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0vI98vgqMmZ"
      },
      "outputs": [],
      "source": [
        "#Separating target variable from dataset\n",
        "y = df['Target']\n",
        "X = df.drop('Target', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pirKKcwNc1dD",
        "outputId": "2bf91e29-2c33-4759-cf9a-b38528c8e58a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Acousticness        float64\n",
              "Danceability        float64\n",
              "Duration            float64\n",
              "Energy              float64\n",
              "Instrumentalness    float64\n",
              "Key                   int64\n",
              "Liveness            float64\n",
              "Loudness            float64\n",
              "Mode                  int64\n",
              "Speechiness         float64\n",
              "Tempo               float64\n",
              "Time_Signature        int64\n",
              "Valence             float64\n",
              "TempoVariability    float64\n",
              "TempoRange          float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Checking data type of each column in our dataframe\n",
        "X.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwWIJlgYfiC3",
        "outputId": "3e7950bf-78cc-43e9-ff66-27611eef6f8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Acousticness', 'Danceability', 'Duration', 'Energy',\n",
              "       'Instrumentalness', 'Key', 'Liveness', 'Loudness', 'Mode',\n",
              "       'Speechiness', 'Tempo', 'Time_Signature', 'Valence', 'TempoVariability',\n",
              "       'TempoRange'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#selecting numeric columns from our dataset\n",
        "numeric_col = X.select_dtypes(include='number').columns\n",
        "numeric_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh5p908yfnhs"
      },
      "outputs": [],
      "source": [
        "#Created a function to standardize all numeric columns in a dataframe\n",
        "std_scaler = StandardScaler()\n",
        "def standardization(df,col):\n",
        "  for i in col:\n",
        "    arr = df[i]\n",
        "    arr = np.array(arr)\n",
        "    df[i] = std_scaler.fit_transform(arr.reshape(len(arr),1))\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZBpJ20WfxKa"
      },
      "outputs": [],
      "source": [
        "#Passing the dataframe and the numeric colums as parameters to the standardization function which standardizes all numeric values in a dataframe\n",
        "df_standardized = standardization(X,numeric_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "oHKmOic3gjTz",
        "outputId": "26392894-2457-4000-9b9e-f7fa1e4efb94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Acousticness  Danceability  Duration    Energy  Instrumentalness       Key  \\\n",
              "0     -0.682956      1.332913 -0.508052 -1.179049         -0.407036 -0.917848   \n",
              "1      0.044243      0.773779  0.983794 -1.535847         -0.464896 -1.191922   \n",
              "2     -0.589746      1.363976 -0.738452 -1.283709         -0.486428 -0.917848   \n",
              "3      1.604177     -0.773161 -0.571307 -1.635750          1.381537 -0.095626   \n",
              "4     -0.028939      0.369959  1.788174 -0.574871          1.388866 -0.095626   \n",
              "\n",
              "   Liveness  Loudness      Mode  Speechiness     Tempo  Time_Signature  \\\n",
              "0 -0.165984 -0.457521  0.795686     3.777457  1.066649        0.124205   \n",
              "1 -0.346011 -0.885152  0.795686    -0.146977  1.442230        0.124205   \n",
              "2 -0.204561 -0.018972  0.795686     2.192503 -1.744977        0.124205   \n",
              "3 -0.634054 -2.172574  0.795686    -0.741893 -1.316813        0.124205   \n",
              "4  1.595710 -1.217193 -1.256777    -0.258593  1.963980        0.124205   \n",
              "\n",
              "    Valence  TempoVariability    TempoRange  \n",
              "0 -0.855011      4.440892e-16 -1.776357e-15  \n",
              "1  0.367140      4.440892e-16 -1.776357e-15  \n",
              "2 -1.312305      4.440892e-16 -1.776357e-15  \n",
              "3 -1.081634      4.440892e-16 -1.776357e-15  \n",
              "4  1.645946      4.440892e-16 -1.776357e-15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae871776-ac99-4b33-b278-e67a12f2967a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acousticness</th>\n",
              "      <th>Danceability</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Energy</th>\n",
              "      <th>Instrumentalness</th>\n",
              "      <th>Key</th>\n",
              "      <th>Liveness</th>\n",
              "      <th>Loudness</th>\n",
              "      <th>Mode</th>\n",
              "      <th>Speechiness</th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Time_Signature</th>\n",
              "      <th>Valence</th>\n",
              "      <th>TempoVariability</th>\n",
              "      <th>TempoRange</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.682956</td>\n",
              "      <td>1.332913</td>\n",
              "      <td>-0.508052</td>\n",
              "      <td>-1.179049</td>\n",
              "      <td>-0.407036</td>\n",
              "      <td>-0.917848</td>\n",
              "      <td>-0.165984</td>\n",
              "      <td>-0.457521</td>\n",
              "      <td>0.795686</td>\n",
              "      <td>3.777457</td>\n",
              "      <td>1.066649</td>\n",
              "      <td>0.124205</td>\n",
              "      <td>-0.855011</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.044243</td>\n",
              "      <td>0.773779</td>\n",
              "      <td>0.983794</td>\n",
              "      <td>-1.535847</td>\n",
              "      <td>-0.464896</td>\n",
              "      <td>-1.191922</td>\n",
              "      <td>-0.346011</td>\n",
              "      <td>-0.885152</td>\n",
              "      <td>0.795686</td>\n",
              "      <td>-0.146977</td>\n",
              "      <td>1.442230</td>\n",
              "      <td>0.124205</td>\n",
              "      <td>0.367140</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.589746</td>\n",
              "      <td>1.363976</td>\n",
              "      <td>-0.738452</td>\n",
              "      <td>-1.283709</td>\n",
              "      <td>-0.486428</td>\n",
              "      <td>-0.917848</td>\n",
              "      <td>-0.204561</td>\n",
              "      <td>-0.018972</td>\n",
              "      <td>0.795686</td>\n",
              "      <td>2.192503</td>\n",
              "      <td>-1.744977</td>\n",
              "      <td>0.124205</td>\n",
              "      <td>-1.312305</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.604177</td>\n",
              "      <td>-0.773161</td>\n",
              "      <td>-0.571307</td>\n",
              "      <td>-1.635750</td>\n",
              "      <td>1.381537</td>\n",
              "      <td>-0.095626</td>\n",
              "      <td>-0.634054</td>\n",
              "      <td>-2.172574</td>\n",
              "      <td>0.795686</td>\n",
              "      <td>-0.741893</td>\n",
              "      <td>-1.316813</td>\n",
              "      <td>0.124205</td>\n",
              "      <td>-1.081634</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.028939</td>\n",
              "      <td>0.369959</td>\n",
              "      <td>1.788174</td>\n",
              "      <td>-0.574871</td>\n",
              "      <td>1.388866</td>\n",
              "      <td>-0.095626</td>\n",
              "      <td>1.595710</td>\n",
              "      <td>-1.217193</td>\n",
              "      <td>-1.256777</td>\n",
              "      <td>-0.258593</td>\n",
              "      <td>1.963980</td>\n",
              "      <td>0.124205</td>\n",
              "      <td>1.645946</td>\n",
              "      <td>4.440892e-16</td>\n",
              "      <td>-1.776357e-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae871776-ac99-4b33-b278-e67a12f2967a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae871776-ac99-4b33-b278-e67a12f2967a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae871776-ac99-4b33-b278-e67a12f2967a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_standardized.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL-cUjLknxf1"
      },
      "source": [
        "**Method 1: Model Evaluation without using validation set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHrkDFK8grKo"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev-n-kGyoNAC"
      },
      "outputs": [],
      "source": [
        "#Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pkAL2Jcoz-F"
      },
      "source": [
        "**Applying Logistic Regression - evaluate on *accuracy* because classes are relatively balanced. Accuary = proportion of predictions that the model got right**\n",
        "\n",
        "When selecting evaluation metrics for classification, it's crucial to consider the real-world implications of different types of errors. The choice of metric should reflect the costs and benefits associated with true positives, false positives, true negatives, and false negatives.\n",
        "\n",
        "For instance, in a medical diagnosis scenario, a false negative (failing to identify a disease when it is present) could have severe consequences, potentially leading to a lack of treatment and worsening health. In this case, a high recall (sensitivity) would be important to minimize false negatives.\n",
        "\n",
        "On the other hand, in a spam detection scenario, a false positive (labeling a legitimate email as spam) could lead to important messages being missed, but it's not as critical as missing a serious disease. Here, precision (ensuring that when we predict spam, we're correct) might be more important.\n",
        "\n",
        "In some cases, both types of errors could be equally costly, in which case a balance between precision and recall, such as the F1 score, might be appropriate.\n",
        "\n",
        "The choice of metric should align with the real-world outcomes and the specific costs associated with different types of prediction errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc6D9fUlVfGZ"
      },
      "source": [
        "**Logisic Regression** is a supervised learning algorithm that is used for classification problems and is simple to implement and easy to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIQ-ksEGowp-",
        "outputId": "c5ee51f3-e421-417b-8d2c-20ccdf81aaef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6650124069478908"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "lr = LogisticRegression(solver='liblinear',multi_class='ovr')\n",
        "lr.fit(X_train, y_train)\n",
        "lr.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "767nhv_pq1Qe"
      },
      "source": [
        "Applying **Decision Trees** which is a supervised learning algorithm that is used for classification problems that uses a tree-like structure to make predictions based on a set of features and criteria. It is simple to understand and interpret and it can handle both numerical and categorical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvXP6LnZq7LD",
        "outputId": "cffe39e1-21e2-4517-b572-1ac3b12887c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6923076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4bSBhC_rStb"
      },
      "source": [
        "Applying **Random Forest** with is a supervised learning algorithm that is used for both classification and regression tasks. It is an ensemble learning method that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random Forests correct for decision trees' habit of overfitting to their training set and are able to handle both numerical and categorical data. They are robust to outliers and can handle unbalanced data well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hii4tUJ3rW9I",
        "outputId": "bbe68a35-7181-459b-ede7-a19283e2e841"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7990074441687345"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8E-uQaWrb1g"
      },
      "source": [
        "**Method 2: Using K Fold Cross Validation**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG5XBeLNhkty"
      },
      "source": [
        "K-fold cross-validation is a technique used for assessing how a machine learning model will generalize to an independent data set. It involves dividing the original sample into 'k' equal sized subsamples or 'folds'. Of the 'k' subsamples, a single subsample is retained as the validation data for testing the model, and the remaining 'k-1' subsamples are used as training data. The cross-validation process is then repeated 'k' times, with each of the 'k' subsamples used exactly once as the validation data. The 'k' results from the folds can then be averaged (or otherwise combined) to produce a single estimation. The advantage of this method is that it matters less how the data gets divided. Every data point gets to be in a test set exactly once, and gets to be in a training set 'k-1' times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R5SCXYcrfjL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMuk42Uoso3G"
      },
      "source": [
        "Applying Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us3CjK0KrwV9",
        "outputId": "30bdcea2-64cb-417f-e9cc-2ada194f3a96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.71287129, 0.5990099 , 0.65671642, 0.64179104, 0.59701493,\n",
              "       0.4079602 , 0.72636816, 0.5721393 , 0.67164179, 0.56716418])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Take k=10 folds for our problem\n",
        "cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X, y,cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqiI_gNFsUYc"
      },
      "source": [
        "cross_val_score return an array with accuracy scores of each split and by default uses Stratified Kfold for splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i34dkEwFss16"
      },
      "source": [
        "Applying Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmLhC-HMsnjM",
        "outputId": "fb2fe0ab-3854-4e75-a728-a18e7f7c88d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72277228, 0.68316832, 0.74129353, 0.64676617, 0.6318408 ,\n",
              "       0.68656716, 0.62686567, 0.6119403 , 0.66169154, 0.62189055])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "cross_val_score(DecisionTreeClassifier(), X, y,cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-X62f68vCZl"
      },
      "source": [
        "Applying Random Forest Ensemble Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntb_L8hgvBo5",
        "outputId": "17ff7a26-92a4-4940-a7c3-6c33bc70b47a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85643564, 0.75742574, 0.84079602, 0.71641791, 0.69651741,\n",
              "       0.62686567, 0.77114428, 0.74626866, 0.74129353, 0.71144279])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "cross_val_score(RandomForestClassifier(), X, y,cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz4Ie6Fqwv05"
      },
      "source": [
        "Hyperparameter Tuning on Random Forest: increase the number of trees or unique predictions trained independently on a random subset of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk_ECYMpx9Yo",
        "outputId": "979d06dd-f07a-4cfb-eb0e-c87f2568460a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7096774193548387"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators = 5)\n",
        "rf.fit(X_train, y_train)\n",
        "rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOj7b2KxzHms",
        "outputId": "b75bbc25-4289-4725-d889-94f26edc220c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.794044665012407"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators = 50)\n",
        "rf.fit(X_train, y_train)\n",
        "rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7-E3TmnzLmP",
        "outputId": "11dba6ab-b4a4-4435-f7be-6a0ef7ff789e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8014888337468983"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators = 100)\n",
        "rf.fit(X_train, y_train)\n",
        "rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GWs9rMlzN8O"
      },
      "source": [
        "As we are tuning the attribute of Random Forest Classifier, we see that the accuracy score is increasing. Thus hyperparameter tuning helps us to fine tune our model to yeild better accuracy/score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5RVtBm8935q"
      },
      "source": [
        "*Tuning other hyperparameters:* Besides n_estimators, there are many other hyperparameters that could be tuned to optimize the model. For example, in a RandomForestClassifier, you could tune max_depth (the maximum depth of the trees), min_samples_split (the minimum number of samples required to split an internal node), and max_features (the number of features to consider when looking for the best split), among others. In XGBoost, you could tune learning_rate, max_depth, min_child_weight, and many others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea1GTNgx3Qyg"
      },
      "source": [
        "**Method 3: Advanced Model Optimization: XGBoost with validation set**\n",
        "\n",
        "XGBoost, short for \"Extreme Gradient Boosting\", is a powerful machine learning algorithm used for both regression and classification tasks. It's based on the concept of 'boosting', which involves training a sequence of weak models, typically decision trees, each one learning from the mistakes of its predecessors.\n",
        "\n",
        "Here's a simple explanation of how XGBoost works for classification:\n",
        "\n",
        "Initialization: XGBoost starts by predicting a constant value for all instances in the dataset. This could be the most frequent class in a classification problem.\n",
        "\n",
        "Sequential Learning: XGBoost then enters a loop where it repeatedly builds new decision trees. Each tree is trained to correct the mistakes made by the entire ensemble of all previous trees.\n",
        "\n",
        "Gradient Boosting: The 'Gradient Boosting' part of XGBoost comes from the fact that each new tree is specifically designed to reduce the 'gradient of the loss'. This means that each tree is trying to correct the errors of the previous ensemble, with more emphasis on instances that were harder to predict.\n",
        "\n",
        "Regularization: XGBoost also includes a regularization term in its objective function that penalizes complex models. This helps to prevent overfitting.\n",
        "\n",
        "Tree Pruning: Unlike other boosting algorithms, XGBoost uses a technique called 'post-pruning', where trees are allowed to grow to their maximum depth during training, and then unnecessary branches are pruned off.\n",
        "\n",
        "Prediction: Once all the trees have been built, making a prediction involves adding up the predictions of all individual trees.\n",
        "\n",
        "The power of XGBoost comes from the fact that it combines the predictive power of hundreds or thousands of individual decision trees, each one helping to correct the mistakes of its predecessors. This allows it to model complex patterns in data and often results in superior predictive performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTV9qld6Duha"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split the data into a training set and a temporary set using an 80-20 split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Then split the training set into a training set and a validation set using an 80-20 split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "N9fVrKB8EDjO",
        "outputId": "6d2eecb2-4010-4b0f-ca9b-a75dd5b24320"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Create an XGBoost classifier object\n",
        "xgb_clf = xgb.XGBClassifier()\n",
        "\n",
        "# Train the classifier using the training data\n",
        "xgb_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-k3IqHCFNXk"
      },
      "source": [
        "We will continue to evaluate on the metric accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmQqMyNfEDiX",
        "outputId": "21dc5a69-bce3-48a6-f261-5560118e3306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 72.36%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict the labels for the validation set\n",
        "y_val_pred = xgb_clf.predict(X_val)\n",
        "\n",
        "# Compute the accuracy of the XGBoost model\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nXkkqDXNO_B"
      },
      "source": [
        "Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a85J-ZZcNrXC"
      },
      "source": [
        "**n_estimators:** This is the number of trees you want to build before taking the maximum voting or averages of predictions. Higher number of trees gives you better performance but makes your code slower. You should choose as high value as your processor can handle because this makes your predictions stronger and more stable.\n",
        "\n",
        "**max_depth:** This indicates how deeply each tree is allowed to grow during any boosting round. A smaller value will make the algorithm more conservative and prevent overfitting but too small values might lead to under-fitting.\n",
        "\n",
        "**learning_rate:** This determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates. Lower values are generally preferred as they make the model robust to the specific characteristics of tree and thus allowing it to generalize well.\n",
        "\n",
        "**min_child_weight:**This parameter refers to the minimum sum of weights of all observations required in a child. This is similar to min_child_leaf in GBM but not exactly. This refers to the minimum sum of weights of observations while GBM has min number of observations for the leaf.\n",
        "\n",
        "**booster:** It's the booster type to use. gbtree, gblinear or dart. gbtree and dart use tree based models while gblinear uses linear functions.\n",
        "\n",
        "**base_score:** It's the initial prediction score of all instances, global bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJZ299UaFL35"
      },
      "source": [
        "**GridSearchCV** allows you to define a grid of possible values for these hyperparameters and then it will automatically perform cross-validation for each combination of parameters to find the best ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "qiEG_b1IEtYa",
        "outputId": "e73b980c-b3b3-4f46-b564-4975548d3ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 3200 candidates, totalling 12800 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False, eval_metric=None,\n",
              "                                     feature_types=None, gamma=None,\n",
              "                                     gpu_id=None, grow_policy=None,\n",
              "                                     importance_type=None,\n",
              "                                     interaction_constraints=None,\n",
              "                                     learning_rate=None,...\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_parallel_tree=None, predictor=None,\n",
              "                                     random_state=None, ...),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'base_score': [0.25, 0.5, 0.75, 0.99],\n",
              "                         'booster': ['gbtree', 'gblinear'],\n",
              "                         'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
              "                         'max_depth': [2, 3, 5, 10, 15],\n",
              "                         'min_child_weight': [1, 2, 3, 4],\n",
              "                         'n_estimators': [50, 100, 150, 200, 250]},\n",
              "             scoring='accuracy', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False, eval_metric=None,\n",
              "                                     feature_types=None, gamma=None,\n",
              "                                     gpu_id=None, grow_policy=None,\n",
              "                                     importance_type=None,\n",
              "                                     interaction_constraints=None,\n",
              "                                     learning_rate=None,...\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_parallel_tree=None, predictor=None,\n",
              "                                     random_state=None, ...),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 0.99],\n",
              "                         &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
              "                         &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n",
              "                         &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
              "                         &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200, 250]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False, eval_metric=None,\n",
              "                                     feature_types=None, gamma=None,\n",
              "                                     gpu_id=None, grow_policy=None,\n",
              "                                     importance_type=None,\n",
              "                                     interaction_constraints=None,\n",
              "                                     learning_rate=None,...\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     n_estimators=100, n_jobs=None,\n",
              "                                     num_parallel_tree=None, predictor=None,\n",
              "                                     random_state=None, ...),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 0.99],\n",
              "                         &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
              "                         &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n",
              "                         &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
              "                         &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150, 200, 250]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "hyperparameter_grid = {\n",
        "    'n_estimators': [50, 100, 150, 200, 250],\n",
        "    'max_depth':[2, 3, 5, 10, 15],\n",
        "    'learning_rate':[0.05, 0.1, 0.15, 0.2],\n",
        "    'min_child_weight':[1, 2, 3, 4],\n",
        "    'booster':['gbtree', 'gblinear'],\n",
        "    'base_score':[0.25, 0.5, 0.75, .99]\n",
        "}\n",
        "\n",
        "# Set up the grid search with 4-fold cross validation\n",
        "xgb_cv = GridSearchCV(estimator=xgb_clf,\n",
        "                      param_grid=hyperparameter_grid,\n",
        "                      cv=4,\n",
        "                      scoring = 'accuracy',\n",
        "                      n_jobs = -1,\n",
        "                      verbose = 1)\n",
        "\n",
        "# Fit the grid search model\n",
        "xgb_cv.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_val, y_val)],verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hyA51rtOL3R"
      },
      "source": [
        "**estimator:** The model for which you want to optimize parameters.\n",
        "param_grid: The dictionary of parameters you want to try (in this case, the hyperparameter_grid).\n",
        "cv: The number of cross-validation folds to use for validating your model.\n",
        "**scoring:** The scoring metric to use when deciding the best parameters. In this case, it's accuracy.\n",
        "**n_jobs:** The number of jobs to run in parallel. -1 means using all processors.\n",
        "**verbose:** Controls the verbosity: the higher, the more messages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best hyperparameters found\n",
        "print(xgb_cv.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_xgb_clf = xgb_cv.best_estimator_\n",
        "\n",
        "# Predict the labels for the validation set\n",
        "y_val_pred = best_xgb_clf.predict(X_val)\n",
        "\n",
        "# Compute the accuracy of the XGBoost model\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsGGepUWvzvU",
        "outputId": "22b0b9d6-9255-43b4-cf6b-727f07637265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'base_score': 0.75, 'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 3, 'n_estimators': 50}\n",
            "Validation Accuracy: 73.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the cell above is taking too long, use **Randomized Search:** Instead of trying out every single combination of hyperparameters (which is what Grid Search does), Randomized Search picks a random subset of the combinations. This can significantly reduce the computation time."
      ],
      "metadata": {
        "id": "5N7Re-ftcxJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n"
      ],
      "metadata": {
        "id": "_7byf6ZTiilS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "ee5fbf24-e91e-4517-e8e2-61ba52379ed0",
        "id": "iovMJRFvhzgj"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 20 folds for each of 10 candidates, totalling 200 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=20,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rat...\n",
              "                                           monotone_constraints=None,\n",
              "                                           n_estimators=100, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           predictor=None, random_state=None, ...),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 0.99],\n",
              "                                        'booster': ['gbtree', 'gblinear'],\n",
              "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
              "                                        'max_depth': [2, 3, 5, 10, 15],\n",
              "                                        'min_child_weight': [1, 2, 3, 4],\n",
              "                                        'n_estimators': [100, 200, 300, 400,\n",
              "                                                         500]},\n",
              "                   scoring='accuracy', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=20,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rat...\n",
              "                                           monotone_constraints=None,\n",
              "                                           n_estimators=100, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           predictor=None, random_state=None, ...),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 0.99],\n",
              "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
              "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n",
              "                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
              "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
              "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
              "                                                         500]},\n",
              "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=20,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rat...\n",
              "                                           monotone_constraints=None,\n",
              "                                           n_estimators=100, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           predictor=None, random_state=None, ...),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 0.99],\n",
              "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
              "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n",
              "                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
              "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
              "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
              "                                                         500]},\n",
              "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Define the grid of hyperparameters to search\n",
        "hyperparameter_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth':[2, 3, 5, 10, 15],\n",
        "    'learning_rate':[0.05, 0.1, 0.15, 0.2],\n",
        "    'min_child_weight':[1, 2, 3, 4],\n",
        "    'booster':['gbtree', 'gblinear'],\n",
        "    'base_score':[0.25, 0.5, 0.75, .99]\n",
        "}\n",
        "\n",
        "# Set up the random search with 10-fold cross validation\n",
        "xgb_cv = RandomizedSearchCV(estimator=xgb_clf,\n",
        "                      param_distributions=hyperparameter_grid,\n",
        "                      cv=20,\n",
        "                      scoring = 'accuracy',\n",
        "                      n_jobs = -1,\n",
        "                      verbose = 1)\n",
        "\n",
        "# Fit the grid search model\n",
        "xgb_cv.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_val, y_val)],verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSQmE2zOEyFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1bf50f6-d663-4995-e18c-c455272f4de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 15, 'learning_rate': 0.1, 'booster': 'gbtree', 'base_score': 0.75}\n",
            "Validation Accuracy: 74.22%\n"
          ]
        }
      ],
      "source": [
        "# Print the best hyperparameters found\n",
        "print(xgb_cv.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_xgb_clf = xgb_cv.best_estimator_\n",
        "\n",
        "# Predict the labels for the validation set\n",
        "y_val_pred = best_xgb_clf.predict(X_val)\n",
        "\n",
        "# Compute the accuracy of the XGBoost model\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G7Yl3mLUv7N"
      },
      "source": [
        "The test set is typically used as the final evaluation of the model. It is supposed to represent unseen data and give an unbiased estimate of the model's performance in the real world.\n",
        "\n",
        "The validation set, on the other hand, is used during the model building and tuning process. It helps in tuning the hyperparameters, selecting the best model, and preventing overfitting on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q04buZXWEz4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b234c6-ee7a-4771-9a81-b3a020e1fd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.94%\n"
          ]
        }
      ],
      "source": [
        "# Predict the labels for the test set\n",
        "y_test_pred = best_xgb_clf.predict(X_test)\n",
        "\n",
        "# Compute the accuracy of the XGBoost model\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OIiCabeUVgi"
      },
      "source": [
        "Let's visualze the results with a confusion matrix on the test predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUQW0vUBUa3r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "3f91b3ed-3c05-412e-cefd-99bfc5dabfa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa346988610>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyo0lEQVR4nO3deXRUdZr/8U8lIQuQhQgkKUggCCIgBoQ2gyv8jAI6CK09NE7UiAhjO0ElytYaNoEobhikoV1pesClW8lR7MZBUIEWUcA4igFZwiKQoEYoEsxWdX9/IKVlQFO5VSmq7vt1zu3Tdbd60ifNk+f5fu/32gzDMAQAAEJWWKADAAAA/kWyBwAgxJHsAQAIcSR7AABCHMkeAIAQR7IHACDEkewBAAhxEYEOwAyXy6VDhw4pNjZWNpst0OEAALxkGIaOHz8uu92usDD/1Z/V1dWqra01fZ/IyEhFR0f7IKLmFdTJ/tChQ0pNTQ10GAAAkw4cOKCOHTv65d7V1dVK79RaZUecpu+VnJys0tLSoEv4QZ3sY2NjJUnz1/VRTOvwAEcD+McrV54f6BAAv6k36rSu8lX3v+f+UFtbq7IjTu3b0llxsU3vHjiOu9Sp317V1taS7JvTqdZ9TOtwxbQO6h8FOKMIW2SgQwD8rjmGYlvH2tQ6tunf41LwDheTIQEAluA0XHKaeBuM03D5LphmRrIHAFiCS4Zcanq2N3NtoPHoHQAAIY7KHgBgCS65ZKYRb+7qwCLZAwAswWkYchpNb8WbuTbQaOMDABDiqOwBAJZg5Ql6JHsAgCW4ZMhp0WRPGx8AgBBHZQ8AsATa+AAAhDhm4wMAgJBFZQ8AsATXD5uZ64MVyR4AYAlOk7PxzVwbaCR7AIAlOA2ZfOud72JpbozZAwAQ4qjsAQCWwJg9AAAhziWbnLKZuj5Y0cYHACDEUdkDACzBZZzczFwfrEj2AABLcJps45u5NtBo4wMAEOKo7AEAlmDlyp5kDwCwBJdhk8swMRvfxLWBRhsfAIAQR2UPALAE2vgAAIQ4p8LkNNHQdvowluZGsgcAWIJhcszeYMweAACcrajsAQCWwJg9AAAhzmmEyWmYGLMP4uVyaeMDABDiqOwBAJbgkk0uEzWuS8Fb2pPsAQCWYOUxe9r4AACEOCp7AIAlmJ+gRxsfAICz2skxexMvwqGNDwAAzlZU9gAAS3CZXBuf2fgAAJzlGLMHACDEuRRm2efsGbMHACDEUdkDACzBadjkNPGaWjPXBhrJHgBgCU6TE/SctPEBAMDZisoeAGAJLiNMLhOz8V3MxgcA4OxGGx8AAIQsKnsAgCW4ZG5Gvct3oTQ7kj0AwBLML6oTvM3w4I0cAAA0CpU9AMASzK+NH7z1MckeAGAJVn6fPckeAGAJVq7sgzdyAADQKCR7AIAlnFpUx8zmjXXr1mnYsGGy2+2y2WwqKio647l33nmnbDab5s+f77G/oqJC2dnZiouLU0JCgsaMGaPKykqvf3aSPQDAElyGzfTmjaqqKmVkZGjhwoW/eN6KFSv04Ycfym63NziWnZ2tbdu2afXq1Vq5cqXWrVuncePGeRWHxJg9AABecTgcHp+joqIUFRXV4LyhQ4dq6NChv3ivgwcPavz48Xr77bd13XXXeRwrKSnRqlWr9PHHH6t///6SpAULFujaa6/VY489dto/Ds6Eyh4AYAkuky38U4vqpKamKj4+3r0VFBQ0LR6XS7fccosmTpyoXr16NTi+ceNGJSQkuBO9JGVlZSksLEybNm3y6ruo7AEAlmD+rXcnrz1w4IDi4uLc+09X1TfGI488ooiICN19992nPV5WVqb27dt77IuIiFBiYqLKysq8+i6SPQAAXoiLi/NI9k2xZcsWPfXUU9q6datsNv8/v08bHwBgCU7ZTG++sn79eh05ckRpaWmKiIhQRESE9u3bp/vuu0+dO3eWJCUnJ+vIkSMe19XX16uiokLJyclefR+VPQDAEnzVxveFW265RVlZWR77Bg8erFtuuUWjR4+WJA0YMEBHjx7Vli1b1K9fP0nS2rVr5XK5lJmZ6dX3kewBAPCDyspK7dq1y/25tLRUxcXFSkxMVFpams455xyP81u0aKHk5GR1795dktSjRw8NGTJEY8eO1eLFi1VXV6fc3FyNGjXKq5n4EskeAGARTslUK97p5fmbN2/WoEGD3J/z8vIkSTk5OVqyZEmj7rFs2TLl5ubqqquuUlhYmG688UYVFhZ6GQnJHgBgEc3dxh84cKAMw2j0+Xv37m2wLzExUcuXL/fqe0+HZA8AsARehAMAAEIWlT0AwBIMk++zN3ifPQAAZzfa+AAAIGRR2QMALKEpr6n9+fXBimQPALCEU2+vM3N9sAreyAEAQKNQ2QMALIE2PgAAIc6lMLlMNLTNXBtowRs5AABoFCp7AIAlOA2bnCZa8WauDTSSPQDAEhizBwAgxBkm33pnsIIeAAA4W1HZAwAswSmbnCZeZmPm2kAj2QMALMFlmBt3dxk+DKaZ0cYHACDEUdlD5R9Hadvzsfr280h9/3W4Bi78RmlZ35/23A+ntdGXr7RW/6nfqedtle79a+9sq4rtLVT9bbii4l1KGVCti+4/qpZJrub6MYBGy87dp5vHH/DYd2BPjMYN7SdJGj9zl/peclSJ7WtVfSJMX3wSpxce66yv9rQMRLjwEZfJCXpmrg00kj1Uf8KmNt1r1fXGKr2X2/aM5+1fHaOvP41UTPv6BseS/61ave90KKadUyfKw7VlXoLev6ethr58xJ+hA02298uW+uPoC9yfnc4f27u7trXWu2+205HDUYqNr9fN4/drzvPbNPqq/nK5gnfc1upcssllYtzdzLWBdlb8mbJw4UJ17txZ0dHRyszM1EcffRTokCylw5XV6jvBobSrT1/NS9KJ8nB99FCCLn/sW4W1aHi8522VatenVq07ONX+olpdMNahr4sj5arzY+CACU6nTd99E+neHN/9+Iv9z1eT9fnmeB05GK3dX7TWX+Z3Unt7jZI6VAcwYqDpAp7sX3nlFeXl5Wn69OnaunWrMjIyNHjwYB05QkV4tjBc0oaJieo15rgSujWs6n+u5miY9rzZSu361p72DwPgbNCh0/f6n/Uf6YV3Ptakx3aoXcrpE3lUjFPX3FCuwwei9HVZVDNHCV86tYKemS1YBTzZP/HEExo7dqxGjx6tnj17avHixWrZsqVeeOGFQIeGH3z+bKxsEdL5t1b+4nlbHo3X8j4d9EpmB1UdDtegP33TTBEC3tnxf7F6fOp5evCOXnp6RlcldajWo8s+U0yrH/+Yve4/D+v1rR+oqHij+l/xnR4YfYHq6wL+TyZMODVmb2YLVgGNvLa2Vlu2bFFWVpZ7X1hYmLKysrRx48YG59fU1MjhcHhs8K9vP2+hkqWxurTgW9l+5Y/aXmOO699XlCvrhSOyhUn/mpwoI4gfVUHo2rwuURtWtdXeHa20dUMbTRvXS63j6nX50B//QH33jXbK/W1fTczurYN7YzR1/na1iGTCKYJTQCfoffPNN3I6nUpKSvLYn5SUpO3btzc4v6CgQDNnzmyu8CCpfHOUqr8N02uD7O59htOmLY8kqGRprG5ce9i9PzrRpehEl+LS6xV/7rd67Uq7vimOVLu+tYEIHWi0quMROrg3Rva0H1v5JyojdKIyQof2xWj7p7H620cf6pKrv9X7b7ULYKQwwyWTa+MH8QS9oJqNP3XqVOXl5bk/OxwOpaamBjCi0Ndl+AmlXFLjse+dMW3VZfgJdb2h6ozXGT8UQM7a4P0/B6wjuqVTKanVWvN15GmP2374Dyr74GaYnI1vkOybpm3btgoPD1d5ebnH/vLyciUnJzc4PyoqSlFRTJDxtboqm47v//FXofKrcFWUtFBkvEut7U5Ft/H8By6shRTT1qn4LifHN7/+NFLffhap9v1qFBnn0vH9ESp+Kl6xaXVq19fzDwXgbHDHpFJtejdR5YeidE77Wt08fr9cLun9le2U3LFaV1z7tbb+q42OVUSobXKtRo77SrXVYfr4/TaBDh0m8Na7AImMjFS/fv20Zs0ajRgxQpLkcrm0Zs0a5ebmBjI0S/n280j9763t3Z83F5z8B+3c31bp0ocrfvX6iGhD+/83RsUL4lR/Ikwt2zllv7xaF97lUPjpCyUgoNom12jyEzsUl1CnYxUttG1LnCaMzNCx71oovIVLF/R3aETOIbWOq9fRb1vo883xyrvpQh2r4BcawSngbfy8vDzl5OSof//+uvjiizV//nxVVVVp9OjRgQ7NMpIza3TrjgO/fuIPfjpOL0ltutfpmqVf+zoswG8ezjv/jMcqjkRp2rhezRgNmgsr6AXQ73//e3399deaNm2aysrK1KdPH61atarBpD0AAMygjR9gubm5tO0BAPCTsyLZAwDgb1ZeG59kDwCwBCu38YN3tgEAAGgUKnsAgCVYubIn2QMALMHKyZ42PgAAIY7KHgBgCVau7En2AABLMGTu8blgfmM3yR4AYAlWruwZswcAIMRR2QMALMHKlT3JHgBgCVZO9rTxAQAIcVT2AABLsHJlT7IHAFiCYdhkmEjYZq4NNNr4AACEOCp7AIAl8D57AABCnJXH7GnjAwAQ4qjsAQCWYOUJeiR7AIAlWLmNT7IHAFiClSt7xuwBAAhxVPYAAEswTLbxg7myJ9kDACzBkGQY5q4PVrTxAQDwg3Xr1mnYsGGy2+2y2WwqKipyH6urq9PkyZPVu3dvtWrVSna7XbfeeqsOHTrkcY+KigplZ2crLi5OCQkJGjNmjCorK72OhWQPALCEUyvomdm8UVVVpYyMDC1cuLDBsRMnTmjr1q3Kz8/X1q1b9frrr2vHjh26/vrrPc7Lzs7Wtm3btHr1aq1cuVLr1q3TuHHjvP7ZaeMDACyhuWfjDx06VEOHDj3tsfj4eK1evdpj39NPP62LL75Y+/fvV1pamkpKSrRq1Sp9/PHH6t+/vyRpwYIFuvbaa/XYY4/Jbrc3OhYqewAAvOBwODy2mpoan9z32LFjstlsSkhIkCRt3LhRCQkJ7kQvSVlZWQoLC9OmTZu8ujfJHgBgCacW1TGzSVJqaqri4+PdW0FBgenYqqurNXnyZN10002Ki4uTJJWVlal9+/Ye50VERCgxMVFlZWVe3Z82PgDAEgzD5Gz8H649cOCAOyFLUlRUlKm46urqNHLkSBmGoUWLFpm615mQ7AEA8EJcXJxHsjfjVKLft2+f1q5d63Hf5ORkHTlyxOP8+vp6VVRUKDk52avvoY0PALCEUxP0zGy+dCrR79y5U++8847OOeccj+MDBgzQ0aNHtWXLFve+tWvXyuVyKTMz06vvorIHAFhCc8/Gr6ys1K5du9yfS0tLVVxcrMTERKWkpOh3v/udtm7dqpUrV8rpdLrH4RMTExUZGakePXpoyJAhGjt2rBYvXqy6ujrl5uZq1KhRXs3El0j2AACLcBk22ZrxrXebN2/WoEGD3J/z8vIkSTk5OZoxY4beeOMNSVKfPn08rnv33Xc1cOBASdKyZcuUm5urq666SmFhYbrxxhtVWFjodewkewAA/GDgwIEyfmFG4C8dOyUxMVHLly83HQvJHgBgCb6ajR+MSPYAAEs4mezNjNn7MJhmxmx8AABCHJU9AMASmns2/tmEZA8AsARD5t5JH8RdfNr4AACEOip7AIAl0MYHACDUWbiPT7IHAFiD2fXtg7iyZ8weAIAQR2UPALAEVtADACDEWXmCHm18AABCHJU9AMAaDJu5SXZBXNmT7AEAlmDlMXva+AAAhDgqewCANbCoDgAAoc3Ks/EblezfeOONRt/w+uuvb3IwAADA9xqV7EeMGNGom9lsNjmdTjPxAADgP0HcijejUcne5XL5Ow4AAPzKym18U7Pxq6urfRUHAAD+ZfhgC1JeJ3un06mHHnpIHTp0UOvWrbVnzx5JUn5+vp5//nmfBwgAAMzxOtnPmTNHS5Ys0bx58xQZGenef8EFF+i5557zaXAAAPiOzQdbcPI62S9dulTPPPOMsrOzFR4e7t6fkZGh7du3+zQ4AAB8hjZ+4x08eFBdu3ZtsN/lcqmurs4nQQEAAN/xOtn37NlT69evb7D/73//u/r27euToAAA8DkLV/Zer6A3bdo05eTk6ODBg3K5XHr99de1Y8cOLV26VCtXrvRHjAAAmGfht955XdkPHz5cb775pt555x21atVK06ZNU0lJid58801dffXV/ogRAACY0KS18S+//HKtXr3a17EAAOA3Vn7FbZNfhLN582aVlJRIOjmO369fP58FBQCAz/HWu8b76quvdNNNN+lf//qXEhISJElHjx7VJZdcopdfflkdO3b0dYwAAMAEr8fs77jjDtXV1amkpEQVFRWqqKhQSUmJXC6X7rjjDn/ECACAeacm6JnZgpTXlf3777+vDz74QN27d3fv6969uxYsWKDLL7/cp8EBAOArNuPkZub6YOV1sk9NTT3t4jlOp1N2u90nQQEA4HMWHrP3uo3/6KOPavz48dq8ebN73+bNm3XPPffoscce82lwAADAvEZV9m3atJHN9uNYRVVVlTIzMxURcfLy+vp6RURE6Pbbb9eIESP8EigAAKZYeFGdRiX7+fPn+zkMAAD8zMJt/EYl+5ycHH/HAQAA/KTJi+pIUnV1tWpraz32xcXFmQoIAAC/sHBl7/UEvaqqKuXm5qp9+/Zq1aqV2rRp47EBAHBWsvBb77xO9pMmTdLatWu1aNEiRUVF6bnnntPMmTNlt9u1dOlSf8QIAABM8LqN/+abb2rp0qUaOHCgRo8ercsvv1xdu3ZVp06dtGzZMmVnZ/sjTgAAzLHwbHyvK/uKigp16dJF0snx+YqKCknSZZddpnXr1vk2OgAAfOTUCnpmtmDldbLv0qWLSktLJUnnn3++Xn31VUknK/5TL8YBAABnD6+T/ejRo/Xpp59KkqZMmaKFCxcqOjpaEyZM0MSJE30eIAAAPmHhCXpej9lPmDDB/d+zsrK0fft2bdmyRV27dtWFF17o0+AAAIB5pp6zl6ROnTqpU6dOvogFAAC/scnkW+98Fknza1SyLywsbPQN77777iYHAwAAfK9Ryf7JJ59s1M1sNltAkv1LF3VUhK1Fs38v0BzePrQ+0CEAfuM47lKb85rpyyz86F2jkv2p2fcAAAQtlssFAAChyvQEPQAAgoKFK3uSPQDAEsyugmepFfQAAEBwobIHAFiDhdv4Tars169fr5tvvlkDBgzQwYMHJUl//etftWHDBp8GBwCAz1h4uVyvk/1rr72mwYMHKyYmRp988olqamokSceOHdPcuXN9HiAAAMFo3bp1GjZsmOx2u2w2m4qKijyOG4ahadOmKSUlRTExMcrKytLOnTs9zqmoqFB2drbi4uKUkJCgMWPGqLKy0utYvE72s2fP1uLFi/Xss8+qRYsfF7K59NJLtXXrVq8DAACgOTT3K26rqqqUkZGhhQsXnvb4vHnzVFhYqMWLF2vTpk1q1aqVBg8erOrqavc52dnZ2rZtm1avXq2VK1dq3bp1GjdunNc/u9dj9jt27NAVV1zRYH98fLyOHj3qdQAAADSLZl5Bb+jQoRo6dOjpb2UYmj9/vh588EENHz5ckrR06VIlJSWpqKhIo0aNUklJiVatWqWPP/5Y/fv3lyQtWLBA1157rR577DHZ7fZGx+J1ZZ+cnKxdu3Y12L9hwwZ16dLF29sBANA8fDRm73A4PLZTw9neKC0tVVlZmbKystz74uPjlZmZqY0bN0qSNm7cqISEBHeil06+bTYsLEybNm3y6vu8TvZjx47VPffco02bNslms+nQoUNatmyZ7r//fv3hD3/w9nYAAASV1NRUxcfHu7eCggKv71FWViZJSkpK8tiflJTkPlZWVqb27dt7HI+IiFBiYqL7nMbyuo0/ZcoUuVwuXXXVVTpx4oSuuOIKRUVF6f7779f48eO9vR0AAM3CV4vqHDhwQHFxce79UVFRJiPzP6+Tvc1m0wMPPKCJEydq165dqqysVM+ePdW6dWt/xAcAgG/46Dn7uLg4j2TfFMnJyZKk8vJypaSkuPeXl5erT58+7nOOHDnicV19fb0qKirc1zdWk1fQi4yMVM+ePXXxxReT6AEA8EJ6erqSk5O1Zs0a9z6Hw6FNmzZpwIABkqQBAwbo6NGj2rJli/uctWvXyuVyKTMz06vv87qyHzRokGy2M89IXLt2rbe3BADA/0y28b3tClRWVnpMaC8tLVVxcbESExOVlpame++9V7Nnz1a3bt2Unp6u/Px82e12jRgxQpLUo0cPDRkyRGPHjtXixYtVV1en3NxcjRo1yquZ+FITkv2p9sIpdXV1Ki4u1ueff66cnBxvbwcAQPNo5uVyN2/erEGDBrk/5+XlSZJycnK0ZMkSTZo0SVVVVRo3bpyOHj2qyy67TKtWrVJ0dLT7mmXLlik3N1dXXXWVwsLCdOONN6qwsNDr0L1O9k8++eRp98+YMaNJq/oAABCKBg4cKMM4818INptNs2bN0qxZs854TmJiopYvX246Fp+99e7mm2/WCy+84KvbAQDgWxZeG99nb73buHGjR+sBAICziZXfZ+91sr/hhhs8PhuGocOHD2vz5s3Kz8/3WWAAAMA3vE728fHxHp/DwsLUvXt3zZo1S9dcc43PAgMAAL7hVbJ3Op0aPXq0evfurTZt2vgrJgAAfK+ZZ+OfTbyaoBceHq5rrrmGt9sBAIJOc7/i9mzi9Wz8Cy64QHv27PFHLAAAwA+8TvazZ8/W/fffr5UrV+rw4cMNXvUHAMBZy4KP3UlejNnPmjVL9913n6699lpJ0vXXX++xbK5hGLLZbHI6nb6PEgAAsyw8Zt/oZD9z5kzdeeedevfdd/0ZDwAA8LFGJ/tTS/5deeWVfgsGAAB/YVGdRvqlt90BAHBWo43fOOedd96vJvyKigpTAQEAAN/yKtnPnDmzwQp6AAAEA9r4jTRq1Ci1b9/eX7EAAOA/Fm7jN/o5e8brAQAITl7PxgcAIChZuLJvdLJ3uVz+jAMAAL9izB4AgFBn4cre67XxAQBAcKGyBwBYg4Ure5I9AMASrDxmTxsfAIAQR2UPALAG2vgAAIQ22vgAACBkUdkDAKyBNj4AACHOwsmeNj4AACGOyh4AYAm2HzYz1wcrkj0AwBos3MYn2QMALIFH7wAAQMiisgcAWANtfAAALCCIE7YZtPEBAAhxVPYAAEuw8gQ9kj0AwBosPGZPGx8AgBBHZQ8AsATa+AAAhDra+AAAIFRR2QMALIE2PgAAoc7CbXySPQDAGiyc7BmzBwAgxFHZAwAsgTF7AABCHW18AAAQqqjsAQCWYDMM2Yyml+dmrg00kj0AwBpo4wMAgFBFZQ8AsARm4wMAEOpo4wMAgFBFZQ8AsATa+AAAhDra+AAAhLZTlb2ZzRtOp1P5+flKT09XTEyMzj33XD300EMyfvK8vmEYmjZtmlJSUhQTE6OsrCzt3LnTxz85yR4AAL945JFHtGjRIj399NMqKSnRI488onnz5mnBggXuc+bNm6fCwkItXrxYmzZtUqtWrTR48GBVV1f7NBba+AAAa2jmNv4HH3yg4cOH67rrrpMkde7cWS+99JI++uijk7czDM2fP18PPvighg8fLklaunSpkpKSVFRUpFGjRpkI1hOVPQDAMnzRwnc4HB5bTU3Nab/rkksu0Zo1a/Tll19Kkj799FNt2LBBQ4cOlSSVlpaqrKxMWVlZ7mvi4+OVmZmpjRs3+vTnprIHAMALqampHp+nT5+uGTNmNDhvypQpcjgcOv/88xUeHi6n06k5c+YoOztbklRWViZJSkpK8rguKSnJfcxXSPYAAGswjJObmeslHThwQHFxce7dUVFRpz391Vdf1bJly7R8+XL16tVLxcXFuvfee2W325WTk9P0OJqAZA8AsARfPWcfFxfnkezPZOLEiZoyZYp77L13797at2+fCgoKlJOTo+TkZElSeXm5UlJS3NeVl5erT58+TQ/0NBizBwDAD06cOKGwMM80Gx4eLpfLJUlKT09XcnKy1qxZ4z7ucDi0adMmDRgwwKexUNkDAKyhmWfjDxs2THPmzFFaWpp69eqlTz75RE888YRuv/12SZLNZtO9996r2bNnq1u3bkpPT1d+fr7sdrtGjBhhItCGSPYAAEuwuU5uZq73xoIFC5Sfn6+77rpLR44ckd1u13/9139p2rRp7nMmTZqkqqoqjRs3TkePHtVll12mVatWKTo6uumBni52wzAzWyGwHA6H4uPjNVDDFWFrEehwAL94+1BxoEMA/MZx3KU25+3RsWPHGjUO3qTv+CFX/Oa3sxXRoulJtL6uWh+veNCvsfoLlT1+0cjcco35Y5lWPNtWi6d3kCSldKrR2GmH1OviKrWINLTl3VgtfLCDjn7DH1w4O332YSv97U/ttfOzlqoob6Hpz5fqkqHH3McfuzdNq19N9Lim30CH5i7f4/781e4oPfuQXV983Er1dTal9/het04qU59LK5vt54BJrI0PNHRexgldd3OF9mz78S/hqBin5r60R4Zh0+T/OFd5w7sqItLQrL+UyhbMr4RCSKs+EaYuvb5X7tyvznhO/0EOvVT8uXub+qd9Hsen5aTL5ZQe+dsuPb1qh7r0/F7Tbk1XxRFqpmDR3Gvjn00CmuzXrVunYcOGyW63y2azqaioKJDh4CeiWzo1+el9mj+xo44fC3fv73XxCSWl1urxe1O1d3uM9m6P0aP3pKlbxvfqcxkVDs5Ov/l/x3Xb5DJd+pNq/udaRBpKbF/v3mITnO5jx74N18E90RqZe0RdelarQ5da3f7AYdV8H6692307tgo/OvWcvZktSAU02VdVVSkjI0MLFy4MZBg4jdy5B/XRmjh9sj7WY3+LSJdkSHW1Nve+uhqbDJfU6+Kq5g4T8Jn/29haI3v30pjLzlfhlI5yVPz4R25colMdz63WO39LVPWJMDnrpbf+eo4S2tap24XfBzBqoHEC2n8aOnSoe43gxqipqfFYg9jhcPgjLMu7cvh36tr7e42/tluDY9u3tFL1iTCNeeCwXnw4RZKhMQ8cVniElNi+rvmDBXyg/0CHLh16VMlptTq8N0ovPpyiB27uovlv7lR4uGSzSQ+/slszb0/XiG69ZQuTEtrWa86yPR4dAJzdfLWoTjAKqjH7goICxcfHu7efr08M89rZa/WHWYf0SG6a6moa/nocq4jQ7P/qrMyrHSra+ZlW7PhcreJc2vl/MTJcttPcETj7DRxxVAMGO5Teo1qXDD2mWUv36MviVvq/D1pLOtm9ffqPHZXQtl6Pr9ilwre+1CVDjmn6ben6tpwx+6Bh+GALUkH1Wzp16lTl5eW5PzscDhK+j3W98Hu1aVevhW9/6d4XHiH1/rcqXT/6G/175wu19f1Yjb6kh+IS6+Wst6nKEa6Xirfp8P7IAEYO+E5Kp1rFJ9br0N4o9b28UsUbWuujd+L095LP1Cr25MPW3S78SlvX9dA7rybq9+OPBDhi4JcFVbKPioo64wsH4BvF61tr3KDzPPbd9+QBHdgVrVcXtpPrJ9W7o+Lkr0/GpceV0LZeH/5vcD13CpzJ14dayPFduHtoqub7k12un618qjCbIVcQV3tWY+U2flAle/jf91Xh2rcjxmNf9YkwHf/ux/3X/L5C+3dG6di3EerR74T+MOugVjzTTl/tZlYyzk7fV4XpUOmPhULZgUjt/jxGsQn1im3j1P88nqzLrjuqNu3rdXhvpJ6bbZc9vUb9Bh6XJPXoV6XW8U49ek+asieUKSra0D+XnaOyA5G6+CrmDgUNH731LhiR7OG1judWa/TUw4pNcKr8QAu9VJik159pG+iwgDP68tOWmvS7ru7Pf55xcoGoq0dWaHzBAZWWRGv139JV5QjXOUn1uuhKh3ImlSky6uQ/7vHnODVn+W4teThFk0d2lbPOpk7dqzXjxVKd26s6ID8T4I2AJvvKykrt2rXL/bm0tFTFxcVKTExUWlpaACPDT/30H0lJemGuXS/MtQcoGsB7GZdU/uKyw3Nf2nPGY6ecl/F9o87D2Ys2foBs3rxZgwYNcn8+NfkuJydHS5YsCVBUAICQZOHlcgOa7AcOHKggfg8PAABBgTF7AIAl0MYHACDUuQyZelYyiJ+zJNkDAKzBwmP2QbVcLgAA8B6VPQDAEmwyOWbvs0iaH8keAGANFl5BjzY+AAAhjsoeAGAJPHoHAECoYzY+AAAIVVT2AABLsBmGbCYm2Zm5NtBI9gAAa3D9sJm5PkjRxgcAIMRR2QMALIE2PgAAoc7Cs/FJ9gAAa2AFPQAAEKqo7AEAlsAKegAAhDra+AAAIFRR2QMALMHmOrmZuT5YkewBANZAGx8AAIQqKnsAgDWwqA4AAKHNysvl0sYHACDEUdkDAKzBwhP0SPYAAGswZO6d9MGb60n2AABrYMweAACELCp7AIA1GDI5Zu+zSJodyR4AYA0WnqBHGx8AgBBHZQ8AsAaXJJvJ64MUyR4AYAnMxgcAACGLyh4AYA0WnqBHsgcAWIOFkz1tfAAAQhyVPQDAGixc2ZPsAQDWwKN3AACENh69AwAAIYvKHgBgDRYes6eyBwBYg8swv3np4MGDuvnmm3XOOecoJiZGvXv31ubNm93HDcPQtGnTlJKSopiYGGVlZWnnzp2+/KklkewBAPCL7777TpdeeqlatGihf/7zn/riiy/0+OOPq02bNu5z5s2bp8LCQi1evFibNm1Sq1atNHjwYFVXV/s0Ftr4AABr8FEb3+FweOyOiopSVFRUg9MfeeQRpaam6sUXX3TvS09P/8ntDM2fP18PPvighg8fLklaunSpkpKSVFRUpFGjRjU91p+hsgcAWITxY8JvyqaTyT41NVXx8fHuraCg4LTf9sYbb6h///76j//4D7Vv3159+/bVs88+6z5eWlqqsrIyZWVluffFx8crMzNTGzdu9OlPTmUPAIAXDhw4oLi4OPfn01X1krRnzx4tWrRIeXl5+uMf/6iPP/5Yd999tyIjI5WTk6OysjJJUlJSksd1SUlJ7mO+QrIHAFiDj9r4cXFxHsn+TFwul/r376+5c+dKkvr27avPP/9cixcvVk5OTtPjaALa+AAAa2jm2fgpKSnq2bOnx74ePXpo//79kqTk5GRJUnl5ucc55eXl7mO+QrIHAMAPLr30Uu3YscNj35dffqlOnTpJOjlZLzk5WWvWrHEfdzgc2rRpkwYMGODTWGjjAwCswXCd3Mxc74UJEybokksu0dy5czVy5Eh99NFHeuaZZ/TMM89Ikmw2m+69917Nnj1b3bp1U3p6uvLz82W32zVixIimx3kaJHsAgDU08wp6v/nNb7RixQpNnTpVs2bNUnp6uubPn6/s7Gz3OZMmTVJVVZXGjRuno0eP6rLLLtOqVasUHR3d9DhPw2YYwbv+n8PhUHx8vAZquCJsLQIdDuAXbx8qDnQIgN84jrvU5rw9OnbsWKMmvTXpO37IFVkd7lRE2OlnzjdGvatG7xxc7NdY/YUxewAAQhxtfACANVj4RTgkewCANRgymex9Fkmzo40PAECIo7IHAFgDbXwAAEKcyyXJxHP2LhPXBhhtfAAAQhyVPQDAGmjjAwAQ4iyc7GnjAwAQ4qjsAQDW4DJk6mF5L19xezYh2QMALMEwXDJMvPXOzLWBRrIHAFiDYZirzhmzBwAAZysqewCANRgmx+yDuLIn2QMArMHlkmwmxt2DeMyeNj4AACGOyh4AYA208QEACG2GyyXDRBs/mB+9o40PAECIo7IHAFgDbXwAAEKcy5Bs1kz2tPEBAAhxVPYAAGswDElmnrMP3sqeZA8AsATDZcgw0cY3SPYAAJzlDJfMVfY8egcAAM5SVPYAAEugjQ8AQKizcBs/qJP9qb+y6lVnap0E4GzmOB68/8AAv8ZRefL3uzmqZrO5ol51vgummQV1sj9+/LgkaYP+EeBIAP9pc16gIwD87/jx44qPj/fLvSMjI5WcnKwNZeZzRXJysiIjI30QVfOyGUE8COFyuXTo0CHFxsbKZrMFOhxLcDgcSk1N1YEDBxQXFxfocACf4ve7+RmGoePHj8tutysszH9zxqurq1VbW2v6PpGRkYqOjvZBRM0rqCv7sLAwdezYMdBhWFJcXBz/GCJk8fvdvPxV0f9UdHR0UCZpX+HROwAAQhzJHgCAEEeyh1eioqI0ffp0RUVFBToUwOf4/UaoCuoJegAA4NdR2QMAEOJI9gAAhDiSPQAAIY5kDwBAiCPZo9EWLlyozp07Kzo6WpmZmfroo48CHRLgE+vWrdOwYcNkt9tls9lUVFQU6JAAnyLZo1FeeeUV5eXlafr06dq6dasyMjI0ePBgHTlyJNChAaZVVVUpIyNDCxcuDHQogF/w6B0aJTMzU7/5zW/09NNPSzr5XoLU1FSNHz9eU6ZMCXB0gO/YbDatWLFCI0aMCHQogM9Q2eNX1dbWasuWLcrKynLvCwsLU1ZWljZu3BjAyAAAjUGyx6/65ptv5HQ6lZSU5LE/KSlJZWVlAYoKANBYJHsAAEIcyR6/qm3btgoPD1d5ebnH/vLyciUnJwcoKgBAY5Hs8asiIyPVr18/rVmzxr3P5XJpzZo1GjBgQAAjAwA0RkSgA0BwyMvLU05Ojvr376+LL75Y8+fPV1VVlUaPHh3o0ADTKisrtWvXLvfn0tJSFRcXKzExUWlpaQGMDPANHr1Doz399NN69NFHVVZWpj59+qiwsFCZmZmBDgsw7b333tOgQYMa7M/JydGSJUuaPyDAx0j2AACEOMbsAQAIcSR7AABCHMkeAIAQR7IHACDEkewBAAhxJHsAAEIcyR4AgBBHsgcAIMSR7AGTbrvtNo0YMcL9eeDAgbr33nubPY733ntPNptNR48ePeM5NptNRUVFjb7njBkz1KdPH1Nx7d27VzabTcXFxabuA6DpSPYISbfddptsNptsNpsiIyPVtWtXzZo1S/X19X7/7tdff10PPfRQo85tTIIGALN4EQ5C1pAhQ/Tiiy+qpqZG//jHP/Tf//3fatGihaZOndrg3NraWkVGRvrkexMTE31yHwDwFSp7hKyoqCglJyerU6dO+sMf/qCsrCy98cYbkn5svc+ZM0d2u13du3eXJB04cEAjR45UQkKCEhMTNXz4cO3du9d9T6fTqby8PCUkJOicc87RpEmT9PPXS/y8jV9TU6PJkycrNTVVUVFR6tq1q55//nnt3bvX/fKVNm3ayGaz6bbbbpN08hXCBQUFSk9PV0xMjDIyMvT3v//d43v+8Y9/6LzzzlNMTIwGDRrkEWdjTZ48Weedd55atmypLl26KD8/X3V1dQ3O+/Of/6zU1FS1bNlSI0eO1LFjxzyOP/fcc+rRo4eio6N1/vnn609/+pPXsQDwH5I9LCMmJka1tbXuz2vWrNGOHTu0evVqrVy5UnV1dRo8eLBiY2O1fv16/etf/1Lr1q01ZMgQ93WPP/64lixZohdeeEEbNmxQRUWFVqxY8Yvfe+utt+qll15SYWGhSkpK9Oc//1mtW7dWamqqXnvtNUnSjh07dPjwYT311FOSpIKCAi1dulSLFy/Wtm3bNGHCBN188816//33JZ38o+SGG27QsGHDVFxcrDvuuENTpkzx+n+T2NhYLVmyRF988YWeeuopPfvss3ryySc9ztm1a5deffVVvfnmm1q1apU++eQT3XXXXe7jy5Yt07Rp0zRnzhyVlJRo7ty5ys/P11/+8hev4wHgJwYQgnJycozhw4cbhmEYLpfLWL16tREVFWXcf//97uNJSUlGTU2N+5q//vWvRvfu3Q2Xy+XeV1NTY8TExBhvv/22YRiGkZKSYsybN899vK6uzujYsaP7uwzDMK688krjnnvuMQzDMHbs2GFIMlavXn3aON99911DkvHdd9+591VXVxstW7Y0PvjgA49zx4wZY9x0002GYRjG1KlTjZ49e3ocnzx5coN7/ZwkY8WKFWc8/uijjxr9+vVzf54+fboRHh5ufPXVV+59//znP42wsDDj8OHDhmEYxrnnnmssX77c4z4PPfSQMWDAAMMwDKO0tNSQZHzyySdn/F4A/sWYPULWypUr1bp1a9XV1cnlcuk///M/NWPGDPfx3r17e4zTf/rpp9q1a5diY2M97lNdXa3du3fr2LFjOnz4sDIzM93HIiIi1L9//wat/FOKi4sVHh6uK6+8stFx79q1SydOnNDVV1/tsb+2tlZ9+/aVJJWUlHjEIUkDBgxo9Hec8sorr6iwsFC7d+9WZWWl6uvrFRcX53FOWlqaOnTo4PE9LpdLO3bsUGxsrHbv3q0xY8Zo7Nix7nPq6+sVHx/vdTwA/INkj5A1aNAgLVq0SJGRkbLb7YqI8Px1b9WqlcfnyspK9evXT8uWLWtwr3bt2jUphpiYGK+vqayslCS99dZbHklWOjkPwVc2btyo7OxszZw5U4MHD1Z8fLxefvllPf74417H+uyzzzb44yM8PNxnsQIwh2SPkNWqVSt17dq10edfdNFFeuWVV9S+ffsG1e0pKSkp2rRpk6644gpJJyvYLVu26KKLLjrt+b1795bL5dL777+vrKysBsdPdRacTqd7X8+ePRUVFaX9+/efsSPQo0cP92TDUz788MNf/yF/4oMPPlCnTp30wAMPuPft27evwXn79+/XoUOHZLfb3d8TFham7t27KykpSXa7XXv27FF2drZX3w+g+TBBD/hBdna22rZtq+HDh2v9+vUqLS3Ve++9p7vvvltfffWVJOmee+7Rww8/rKKiIm3fvl133XXXLz4j37lzZ+Xk5Oj2229XUVGR+56vvvqqJKlTp06y2WxauXKlvv76a1VWVio2Nlb333+/JkyYoL/85S/avXu3tm7dqgULFrgnvd15553auXOnJk6cqB07dmj58uVasmSJVz9vt27dtH//fr388svavXu3CgsLTzvZMDo6Wjk5Ofr000+1fv163X333Ro5cqSSk5MlSTNnzlRBQYEKCwv15Zdf6rPPPtOLL76oJ554wqt4APgPyR74QcuWLbVu3TqlpaXphhtuUI8ePTRmzBhVV1e7K/377rtPt9xyi3JycjRgwADFxsbqt7/97S/ed9GiRfrd736nu+66S+eff77Gjh2rqqoqSVKHDh00c+ZMTZkyRUlJScrNzZUkPfTQQ8rPz1dBQYF69OihIUOG6K233lJ6erqkk+Por732moqKipSRkaHFixdr7ty5Xv28119/vSZMmKDc3Fz16dNHH3zwgfLz8xuc17VrV91www269tprdc011+jCCy/0eLTujjvu0HPPPacXX3xRvXv31pVXXqklS5a4YwUQeDbjTDOLAABASKCyBwAgxJHsAQAIcSR7AABCHMkeAIAQR7IHACDEkewBAAhxJHsAAEIcyR4AgBBHsgcAIMSR7AEACHEkewAAQtz/B/awcvfJhMb0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_test_pred = best_xgb_clf.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Display the confusion matrix\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=best_xgb_clf.classes_)\n",
        "cmd.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What are your observations about our model comparrisons?\n"
      ],
      "metadata": {
        "id": "WgX7XCU1GFB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasons why a basic Random Forest model with n_estimators=100 is outperforming more complex models:**\n",
        "\n",
        "**Overfitting:** More complex models, such as gradient boosting or deep learning models, have a higher capacity and can therefore fit the training data more closely. However, this can lead to overfitting, where the model learns the noise in the training data and performs poorly on unseen data.\n",
        "\n",
        "**Hyperparameters:** The performance of complex models can be highly dependent on their hyperparameters. If these are not tuned correctly, the model may perform poorly. In contrast, Random Forest models are often quite robust to the choice of hyperparameters.\n",
        "\n",
        "**Data characteristics:** Random Forests can perform very well on certain types of data. For example, they can handle categorical variables and interactions between features well, and they are not affected by feature scaling. If your data has these characteristics, a Random Forest may outperform more complex models.\n",
        "\n",
        "**Noise:** If your data is noisy, simpler models can often perform better because they are less likely to fit the noise in the data.\n",
        "\n",
        "**Model Complexity vs. Data Complexity:** If the underlying data pattern is not very complex, simpler models like Random Forest can capture the pattern well enough and there might not be much benefit in using a more complex model.\n",
        "\n",
        "More complex does not always mean better. It's always a good idea to start with simpler models and only move to more complex ones if the simpler models are not sufficient."
      ],
      "metadata": {
        "id": "C1GASscpG3-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How do we interpret the results in the context of our problem?"
      ],
      "metadata": {
        "id": "GY3t3zPrHsJb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI5X0le2WA-B"
      },
      "source": [
        "##Conclusion\n",
        "In this notebook, we have covered several important topics in machine learning, including:\n",
        "\n",
        "**Important libraries: **We have used several important Python libraries such as pandas, numpy, sklearn, matplotlib, and seaborn.\n",
        "\n",
        "**Model selection:** We have trained and evaluated four different models - Logistic Regression, Decision Tree, Random Forest, and XGBoost.\n",
        "\n",
        "**Data Scaling:** We have used StandardScaler to scale our data.\n",
        "\n",
        "**Data Splitting:** We have split our data into training, validation, and test sets.\n",
        "\n",
        "**Model Comparison:** We have compared the performance of our models using accuracy as the metric.\n",
        "\n",
        "**Advanced Model Building:** We have used advanced techniques such as hyperparameter tuning and model optimization to improve the performance of our models.\n",
        "\n",
        "**Hyperparameter Tuning:** We have used GridSearchCV to tune the hyperparameters of our XGBoost model.\n",
        "\n",
        "**Model Optimization:** We have optimized our XGBoost model by finding the best hyperparameters.\n",
        "\n",
        "**Evaluation Metrics:** We have used accuracy as our evaluation metric and also generated a confusion matrix to evaluate our model's performance.\n",
        "\n",
        "**Testing Accuracy:** We have evaluated the final performance of our model on the test set.\n",
        "\n",
        "Through this process, we have gained a deeper understanding of how to build, tune, and evaluate machine learning models in a data science project. We have also seen how different models perform on the same dataset and learned how to optimize our models for better performance.\n",
        "\n",
        "***Finding the right approach for your and knowing  what machine learning tools to use for your solitions is the key to a successful data science project.***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}